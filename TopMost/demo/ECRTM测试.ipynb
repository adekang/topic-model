{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T13:18:52.992257Z",
     "start_time": "2024-09-05T13:18:52.975061Z"
    }
   },
   "source": [
    "from topmost.data import download_dataset\n",
    "\n",
    "device = \"cuda\"  # or \"cpu\"\n",
    "dataset_dir = \"./datasets/20NG\""
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "95ebbb0c98424a58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T07:55:29.386108Z",
     "start_time": "2024-08-24T07:55:29.381108Z"
    }
   },
   "source": "# download_dataset('Wikitext-103', cache_path='./datasets')",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "786d7e5379cc3ebe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T13:18:55.250830Z",
     "start_time": "2024-09-05T13:18:54.741618Z"
    }
   },
   "source": [
    "########################### Neural Topic Models ####################################\n",
    "# dataset for neural topic models.\n",
    "# For combinedTM, add contextual_embed=True.\n",
    "import topmost\n",
    "\n",
    "dataset = topmost.data.BasicDataset(dataset_dir, read_labels=True, device=device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size:  11314\n",
      "test_size:  7532\n",
      "vocab_size:  5000\n",
      "average length: 110.543\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "ad66018b4694eb47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T12:04:59.749399Z",
     "start_time": "2024-09-05T12:04:59.707480Z"
    }
   },
   "source": [
    "# model = topmost.models.ECRTM(dataset.vocab_size, pretrained_WE=dataset.pretrained_WE)\n",
    "model = topmost.models.ETM(dataset.vocab_size, pretrained_WE=dataset.pretrained_WE)\n",
    "model = model.to(device)\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "1d09cf8638413caa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T13:19:21.017819Z",
     "start_time": "2024-09-05T13:18:57.128433Z"
    }
   },
   "source": [
    "# create a trainer\n",
    "# trainer = topmost.trainers.BasicTrainer(model, dataset, verbose=True)\n",
    "trainer = topmost.trainers.BERTopicTrainer(dataset)\n",
    "\n",
    "# train the model\n",
    "top_words, train_theta = trainer.train()"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T13:20:02.667907Z",
     "start_time": "2024-09-05T13:19:25.153580Z"
    }
   },
   "cell_type": "code",
   "source": [
    " ########################### Evaluate ####################################\n",
    "# 获取训练集和测试集的theta (doc-topic分布)\n",
    "train_theta, test_theta = trainer.export_theta()\n",
    "\n",
    "# evaluate topic diversity\n",
    "TD = topmost.evaluations.compute_topic_diversity(top_words)\n",
    "print(f\"TD: {TD:.5f}\")\n",
    "\n",
    "TC = topmost.evaluations.compute_topic_coherence(dataset.train_texts, dataset.vocab, top_words)\n",
    "print(f\"TC: {TC:.5f}\")\n",
    "# evaluate clustering\n",
    "\n",
    "results = topmost.evaluations.evaluate_clustering(test_theta, dataset.test_labels)\n",
    "print(results)\n",
    "\n",
    "# evaluate classification\n",
    "results = topmost.evaluations.evaluate_classification(train_theta, test_theta, dataset.train_labels,\n",
    "                                                      dataset.test_labels)\n",
    "print(results)"
   ],
   "id": "347b2c3e1ccbefff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TD: 0.66667\n",
      "TC: 0.60239\n",
      "{'Purity': 0.4115772703133298, 'NMI': 0.3687523669885181}\n",
      "{'acc': 0.539166224110462, 'macro-F1': 0.533141206688229}\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T06:57:13.315135Z",
     "start_time": "2024-09-05T06:57:13.255902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "########################### test new documents ####################################\n",
    "import torch\n",
    "from topmost.preprocessing import Preprocessing\n",
    "\n",
    "preprocessing = Preprocessing()\n",
    "\n",
    "new_docs = [\n",
    "    \"This is a new document about space, including words like space, satellite, launch, orbit.\",\n",
    "    \"This is a new document about Microsoft Windows, including words like windows, files, dos.\"\n",
    "]\n",
    "\n",
    "parsed_new_docs, new_bow = preprocessing.parse(new_docs, vocab=dataset.vocab)\n",
    "new_theta = trainer.test(torch.as_tensor(new_bow, device=device).float())\n",
    "\n",
    "print(new_theta.argmax(1))"
   ],
   "id": "db753688a1b39656",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing texts: 100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 13\u001B[0m\n\u001B[0;32m      7\u001B[0m new_docs \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis is a new document about space, including words like space, satellite, launch, orbit.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis is a new document about Microsoft Windows, including words like windows, files, dos.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     10\u001B[0m ]\n\u001B[0;32m     12\u001B[0m parsed_new_docs, new_bow \u001B[38;5;241m=\u001B[39m preprocessing\u001B[38;5;241m.\u001B[39mparse(new_docs, vocab\u001B[38;5;241m=\u001B[39mdataset\u001B[38;5;241m.\u001B[39mvocab)\n\u001B[1;32m---> 13\u001B[0m new_theta \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnew_bow\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(new_theta\u001B[38;5;241m.\u001B[39margmax(\u001B[38;5;241m1\u001B[39m))\n",
      "File \u001B[1;32mD:\\software\\anaconda\\envs\\topic-model\\lib\\site-packages\\topmost\\trainers\\basic\\BERTopic_trainer.py:17\u001B[0m, in \u001B[0;36mBERTopicTrainer.test\u001B[1;34m(self, texts)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtest\u001B[39m(\u001B[38;5;28mself\u001B[39m, texts):\n\u001B[1;32m---> 17\u001B[0m     theta, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapproximate_distribution\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m theta\n",
      "File \u001B[1;32mD:\\software\\anaconda\\envs\\topic-model\\lib\\site-packages\\bertopic\\_bertopic.py:1291\u001B[0m, in \u001B[0;36mBERTopic.approximate_distribution\u001B[1;34m(self, documents, window, stride, min_similarity, batch_size, padding, use_embedding_model, calculate_tokens, separator)\u001B[0m\n\u001B[0;32m   1289\u001B[0m \u001B[38;5;66;03m# Extract tokens\u001B[39;00m\n\u001B[0;32m   1290\u001B[0m analyzer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvectorizer_model\u001B[38;5;241m.\u001B[39mbuild_tokenizer()\n\u001B[1;32m-> 1291\u001B[0m tokens \u001B[38;5;241m=\u001B[39m [analyzer(document) \u001B[38;5;28;01mfor\u001B[39;00m document \u001B[38;5;129;01min\u001B[39;00m doc_set]\n\u001B[0;32m   1293\u001B[0m \u001B[38;5;66;03m# Extract token sets\u001B[39;00m\n\u001B[0;32m   1294\u001B[0m all_sentences \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32mD:\\software\\anaconda\\envs\\topic-model\\lib\\site-packages\\bertopic\\_bertopic.py:1291\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m   1289\u001B[0m \u001B[38;5;66;03m# Extract tokens\u001B[39;00m\n\u001B[0;32m   1290\u001B[0m analyzer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvectorizer_model\u001B[38;5;241m.\u001B[39mbuild_tokenizer()\n\u001B[1;32m-> 1291\u001B[0m tokens \u001B[38;5;241m=\u001B[39m [\u001B[43manalyzer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocument\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m document \u001B[38;5;129;01min\u001B[39;00m doc_set]\n\u001B[0;32m   1293\u001B[0m \u001B[38;5;66;03m# Extract token sets\u001B[39;00m\n\u001B[0;32m   1294\u001B[0m all_sentences \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[1;31mTypeError\u001B[0m: expected string or bytes-like object"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T07:55:38.443615Z",
     "start_time": "2024-08-24T07:55:38.432615Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e9c8bf4ca22bc50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T07:55:38.847342Z",
     "start_time": "2024-08-24T07:55:38.835343Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5883dda82e891403",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T07:55:39.223124Z",
     "start_time": "2024-08-24T07:55:39.218125Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "aea1641aa52c3076",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T07:55:39.410592Z",
     "start_time": "2024-08-24T07:55:39.399254Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9e0741c3c9583325",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "98e07dc1b11210a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
